{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21405f72-3231-43da-8c80-ea4b008f96cf",
   "metadata": {},
   "source": [
    "# Integrations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6efdd4c-dee2-4967-8e39-9b01d435f5ef",
   "metadata": {},
   "source": [
    "## OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eba42f5-3be7-499b-9d42-4b42e127b144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate, LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73802d5-b7e4-4a43-925a-2fc24797787a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate(template = template, input_variables = [\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63315f54-d15f-4136-898a-639304bcf72b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6557a49-1d06-4f62-8618-0a2ece9e4c73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(prompt = prompt, llm = llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0d7cba-51c7-4f6e-8f40-8e9db94ffe37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"Which team won the IPL trophy in the year Virat Kohli started playing international cricket ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97f3c76-0e59-41ab-9ec4-c54ad60dfa83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_chain.run(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09d7a93-1a4f-40b7-927d-f99cb17d1edb",
   "metadata": {},
   "source": [
    "## Huggingface Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c37acc-a4f5-41dc-866b-a11c8a9568dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a3df4b-ea38-4250-bc28-d3c26d154d8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HUGGINGFACEHUB_API_TOKEN = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d10cb89-f63b-4963-9021-7d5ad0e8c822",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45b3e0c-e537-42c5-b658-7bf780fd6e00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e4e344-4473-4c81-b142-09aea3f343a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56dbdc2-1358-4a00-a77a-99133840decd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# These are some generative models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2306d8e8-dae7-4754-af21-c1f0aa259ccb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repo_id = \"distilgpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6508492a-063a-417d-aa23-edb3c28adde4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = HuggingFaceHub(repo_id = repo_id, model_kwargs = {\"temperature\": 0.1, \"max_length\": 64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb1699d-9b7b-4b28-8805-d0c9bec608f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a930e77-a0d5-457e-9d2e-0f11b85972b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template = template, input_variables = [\"question\"])\n",
    "\n",
    "llm_chain = LLMChain(prompt = prompt, llm = llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766eb58d-ccd3-4925-a276-3d8973b5e8fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"Who won the FIFA World Cup in the year 1994?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ff82e7-6214-4e47-b99e-55b86d2e6c0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7911720e-bca0-4318-9d89-f4fd1af9b904",
   "metadata": {},
   "source": [
    "#### Other organizations on Huggingface Hub-\n",
    "\n",
    "1. Stability AI\n",
    "    \"stabilityai/stablelm-tuned-alpha-3b\", stabilityai/stablelm-base-alpha-3b\n",
    "\n",
    "2. DataBricks\n",
    "    databricks/dolly-v2-3b\n",
    "\n",
    "3. Writer\n",
    "    Writer/camel-5b-hf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fef383-5790-4fcb-86ee-f0c69f3973ea",
   "metadata": {},
   "source": [
    "### Huggingface Local Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1628ff97-260f-43ef-931c-8f2a8fdb8d4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bee4fb-0c87-431e-afb6-af66e5b4f95f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = HuggingFacePipeline.from_model_id(model_id=\"bigscience/bloom-1b7\", task=\"text-generation\", model_kwargs={\"temperature\":0, \"max_length\":64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7822d4-e26b-476f-b4a5-ca83198ffd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate,  LLMChain\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "question = \"What is electroencephalography?\"\n",
    "\n",
    "print(llm_chain.run(question))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global_venv",
   "language": "python",
   "name": "global_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
