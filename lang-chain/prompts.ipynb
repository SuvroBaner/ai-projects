{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8166e2e-c628-48fd-92f6-75c977efe410",
   "metadata": {},
   "source": [
    "### Prompts\n",
    "\n",
    "In this notebook we will go over the following topics-\n",
    "\n",
    "1. Prompt Templated\n",
    "2. Connecting to Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7efa129b-6954-4021-91d0-8ac0b8c845a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62d04f2b-9485-48dd-8926-f2f66df0916b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nI want you to act as a naming consultant for new companies. What is a good name for a company that makes colorful gloves?\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "I want you to act as a naming consultant for new companies. What is a good name for a company that makes {product}?\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables = [\"product\"],\n",
    "    template = template,\n",
    ")\n",
    "\n",
    "prompt.format(product = \"colorful gloves\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f32e200-3bdd-4ad7-8da8-f36cb5a74e9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['adjective', 'content'], output_parser=None, partial_variables={}, template='Tell me a {adjective} joke about {content}.', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"Tell me a {adjective} joke about {content}.\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d7dd7a9-a393-448c-b64f-9c3e94a30034",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about chickens.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.format(adjective = \"funny\", content = \"chickens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb00ff6d-9bfb-42bb-8caf-c4da2546a4f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Serialize the prompt template -\n",
    "prompt_template.save(\"test_prompt.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f3fa401-fd61-42ab-bc21-edb390b3ddca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import load_prompt\n",
    "loaded_prompt = load_prompt('test_prompt.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a57bb5d-d67d-4b3c-9f21-4f996f8ebd35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert prompt_template == loaded_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8846b199-bec1-4c1e-960a-969e7bc19cf4",
   "metadata": {},
   "source": [
    "Useful prompts from langchain : https://github.com/hwchase17/langchain-hub/tree/master/prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffda4a25-6616-42fb-8a6f-b62b801dbd9b",
   "metadata": {},
   "source": [
    "### Pass few shot examples to a prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e312a82-d3f0-41f8-b14c-9b88eb19fe5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9afceaad-3f85-49df-8c9a-130d33c2cc51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create the list of few shot examples -\n",
    "examples = [\n",
    "    {\"word\": \"happy\", \"antonym\": \"sad\"},\n",
    "    {\"word\": \"tall\", \"antonym\": \"short\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af688c99-b081-4c37-9db5-e5b0af910bd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_formatter_template = \"\"\"\n",
    "Word: {word}\n",
    "Antonym: {antonym}\\n\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables = [\"word\", \"antonym\"],\n",
    "    template = example_formatter_template,\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples = examples,\n",
    "    example_prompt = example_prompt,\n",
    "    prefix = \"Give the antonym of every input\",\n",
    "    suffix = \"Word: {input}\\nAntonym:\",\n",
    "    input_variables = [\"input\"],\n",
    "    example_separator = \"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "552f7a1b-342f-44a9-9c6f-961b2ce21bda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "\n",
      "Word: happy\n",
      "Antonym: sad\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Word: tall\n",
      "Antonym: short\n",
      "\n",
      "\n",
      "\n",
      "Word: little\n",
      "Antonym:\n"
     ]
    }
   ],
   "source": [
    "print(few_shot_prompt.format(input = \"little\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078bb2ee-1445-4218-8005-f1cd8f906cb4",
   "metadata": {},
   "source": [
    "### large number of examples -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4613411-d2a8-4237-97bf-b263ebd115b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts.example_selector import LengthBasedExampleSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "720a611f-108e-4798-b26c-473d135d9da9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example = [\n",
    "    {\"word\": \"happy\", \"antonym\": \"sad\"},\n",
    "    {\"word\": \"tall\", \"antonym\": \"short\"},\n",
    "    {\"word\": \"energetic\", \"antonym\": \"lethargic\"},\n",
    "    {\"word\": \"sunny\", \"antonym\": \"gloomy\"},\n",
    "    {\"word\": \"windy\", \"antonym\": \"calm\"},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0d9bc4d-0491-4476-b2b9-cc5c695cf767",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples = examples,\n",
    "    example_prompt = example_prompt,\n",
    "    max_length = 25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8225ed88-313b-4578-ad41-56bf64c25753",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dynamic_prompt = FewShotPromptTemplate(\n",
    "    example_selector = example_selector,\n",
    "    example_prompt = example_prompt,\n",
    "    prefix = \"Give the antonym for every input\",\n",
    "    suffix = \"Word: {input}\\nAntonym:\",\n",
    "    input_variables = [\"input\"],\n",
    "    example_separator = \"\\n\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bf3178f-ef24-4e25-87fd-08ffc2651a3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym for every input\n",
      "\n",
      "\n",
      "Word: happy\n",
      "Antonym: sad\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Word: tall\n",
      "Antonym: short\n",
      "\n",
      "\n",
      "\n",
      "Word: big\n",
      "Antonym:\n"
     ]
    }
   ],
   "source": [
    "print(dynamic_prompt.format(input = \"big\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5134b221-38e6-4c33-acdb-28ca43f35842",
   "metadata": {},
   "source": [
    "## Connecting to Feature Store\n",
    "Feature store makes sure that the data fed into models is up-to-date and relevant. \n",
    "\n",
    "In order to personalize LLM applications, you may need to combine LLM with up-to-date information about particular users. Langchain facilitates it well. It provides an easy way to combine that data with the LLMs.\n",
    "\n",
    "Connect prompt template to feature stores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b0edd0-db68-4f5d-ba0b-6c039b31470f",
   "metadata": {},
   "source": [
    "### Feast - It is an opensource feature store. \n",
    "\n",
    "GitHub: https://github.com/feast-dev/feast\n",
    "More information : https://docs.feast.dev/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b3bea66-4606-4d9c-b1f4-4691194e7a6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from feast import FeatureStore\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e31e01af-0eb6-4db2-be36-aad9412ccbf7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   driver_id           event_timestamp  conv_rate  acc_rate  avg_daily_trips\n",
      "0       1001 2021-04-12 10:59:42+00:00   0.121119  0.320860              201\n",
      "1       1002 2021-04-12 08:12:10+00:00   0.197364  0.254644              519\n",
      "2       1003 2021-04-12 16:40:26+00:00   0.976411  0.282935              351\n",
      "3       1004 2021-04-12 15:01:12+00:00   0.802593  0.971781              140\n"
     ]
    }
   ],
   "source": [
    "entity_df = pd.DataFrame.from_dict({\n",
    "    \"driver_id\": [1001, 1002, 1003, 1004],\n",
    "    \"event_timestamp\": [\n",
    "        datetime(2021, 4, 12, 10, 59, 42),\n",
    "        datetime(2021, 4, 12, 8,  12, 10),\n",
    "        datetime(2021, 4, 12, 16, 40, 26),\n",
    "        datetime(2021, 4, 12, 15, 1 , 12)\n",
    "    ]\n",
    "})\n",
    "\n",
    "store = FeatureStore(repo_path = \"./../my_feature_repo/feature_repo/\")\n",
    "\n",
    "training_df = store.get_historical_features(\n",
    "    entity_df=entity_df,\n",
    "    features = [\n",
    "        'driver_hourly_stats:conv_rate',\n",
    "        'driver_hourly_stats:acc_rate',\n",
    "        'driver_hourly_stats:avg_daily_trips'\n",
    "    ],\n",
    ").to_df()\n",
    "\n",
    "print(training_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59b0aaf3-dcb1-4450-9313-247d4138aabf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Load feature values into your online store\n",
    "\n",
    "#CURRENT_TIME=$(date -u +\"%Y-%m-%dT%H:%M:%S\")\n",
    "#feast materialize-incremental $CURRENT_TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a880e4a5-df2b-42cd-a355-29f98447d609",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from feast import FeatureStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3549026c-b9ad-46b6-be75-6c44cc2a2930",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "store = FeatureStore(repo_path = \"./../my_feature_repo/feature_repo/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9f751b3-0f04-45af-9596-04be946e86d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc_rate': [0.2518860697746277],\n",
      " 'avg_daily_trips': [873],\n",
      " 'conv_rate': [0.2898779809474945],\n",
      " 'driver_id': [1001]}\n"
     ]
    }
   ],
   "source": [
    "# Retrieves the latest online feature data.\n",
    "\n",
    "feature_vector = store.get_online_features(\n",
    "    features = [\n",
    "        'driver_hourly_stats:conv_rate',\n",
    "        'driver_hourly_stats:acc_rate',\n",
    "        'driver_hourly_stats:avg_daily_trips'\n",
    "    ],\n",
    "    entity_rows = [{\"driver_id\": 1001}]\n",
    ").to_dict()\n",
    "\n",
    "pprint(feature_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c2c7a5-6c75-418a-adbf-77ad6da1fcb3",
   "metadata": {},
   "source": [
    "Here we will set up a custom FeatPromptTemplate. This prompt template will take in a driver id, look up their stats, and format those stats into a prompt.\n",
    "\n",
    "Note that the input to this prompt template is just driver_id, since that is the only user defined piece (all other variables are looked up inside the prompt template.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6da5938b-321e-47dc-a562-e9c1d63007e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate, StringPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87638cde-844d-46db-ad5a-1f9d03349a3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\" Given the driver's up to date stats, write them note relaying those stats to them.\n",
    "If they have a conversation rate above 0.5, give them a compliment. Otherwise, make a silly joke about chickens at the end to make them feel better.\n",
    "\n",
    "Here are the driver stats:\n",
    "Conversation rate: {conv_rate}\n",
    "Acceptance rate: {acc_rate}\n",
    "Average Daily Trips: {avg_daily_trips}\n",
    "\n",
    "Your response:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "012685e1-4375-46c5-8348-172debe2849b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FeastPromptTemplate(StringPromptTemplate):\n",
    "    \n",
    "    def format(self, **kwargs) -> str:\n",
    "        driver_id = kwargs.pop(\"driver_id\")\n",
    "        feature_vector = store.get_online_features(\n",
    "            features = [\n",
    "                'driver_hourly_stats:conv_rate',\n",
    "                'driver_hourly_stats:acc_rate',\n",
    "                'driver_hourly_stats:avg_daily_trips'      \n",
    "            ],\n",
    "            entity_rows = [{\"driver_id\": 1001}]\n",
    "        ).to_dict()\n",
    "        kwargs[\"conv_rate\"] = feature_vector[\"conv_rate\"][0]\n",
    "        kwargs[\"acc_rate\"] = feature_vector[\"acc_rate\"][0]\n",
    "        kwargs[\"avg_daily_trips\"] = feature_vector[\"avg_daily_trips\"][0]\n",
    "        return prompt.format(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ecb3f18e-7db1-4b3c-a6c0-3535718184da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Given the driver's up to date stats, write them note relaying those stats to them.\n",
      "If they have a conversation rate above 0.5, give them a compliment. Otherwise, make a silly joke about chickens at the end to make them feel better.\n",
      "\n",
      "Here are the driver stats:\n",
      "Conversation rate: 0.2898779809474945\n",
      "Acceptance rate: 0.2518860697746277\n",
      "Average Daily Trips: 873\n",
      "\n",
      "Your response:\n"
     ]
    }
   ],
   "source": [
    "prompt_template = FeastPromptTemplate(input_variables = [\"driver_id\"])\n",
    "print(prompt_template.format(driver_id = 1002))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4a4e47c8-1ba3-4aea-8b0f-d4bb125614a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use in a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "189e108a-d661-4491-9853-1ba8cc8a49a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dfb963db-f018-412e-adf6-4f8b353cfeb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = LLMChain(llm = ChatOpenAI(), prompt = prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "47dc1e22-6ac7-4bf6-b1aa-9e33e8bf9209",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello there! Just wanted to give you an update on your stats. Your acceptance rate is currently at 0.2518860697746277 and your average daily trips are going strong at 873. While your conversation rate is at 0.2898779809474945, don't worry, there's always room for improvement. If it makes you feel any better, I heard chickens are great at conversation too! Keep up the good work!\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(1001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef6cc07-8d28-4c93-8732-5b849a16413f",
   "metadata": {},
   "source": [
    "### Tecton : \n",
    "Tecton is a fully managed feature platform built to orchestrate the complete ML feature lifecycle, from transformation to online serving, with enterprise-grade SLAs.\n",
    "\n",
    "https://www.tecton.ai/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7920462-c3be-4618-a92f-3788fe4b71ea",
   "metadata": {},
   "source": [
    "### Custom Prompt Template\n",
    "\n",
    "There are two kinds of prompt templates available -\n",
    "1. String prompt template\n",
    "2. Chat prompt template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2116bfa8-fd53-4560-a47a-299557c33910",
   "metadata": {},
   "source": [
    "#### String Prompt template\n",
    "\n",
    "Here we will create a custom prompt template that takes in the function name as input and formats the prompt to provide the source code of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5f7e8a66-78c5-4754-9049-29109c43299c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9e2ae158-427e-47e9-beef-fc627a2161c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_source_code(function_name):\n",
    "    # get the source code of the function\n",
    "    return inspect.getsource(function_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a61b59cf-f5f3-41c2-bba8-21cefa1bb1c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import StringPromptTemplate\n",
    "from pydantic import BaseModel, validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bdf1e378-765c-4d3a-98b3-4ec019d04142",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FunctionExplainerPromptTemplate(StringPromptTemplate, BaseModel):\n",
    "    \"\"\" A custom prompt template that takes in the function name as input, and formats the prompt template to provide the source code of the function . \"\"\"\n",
    "    \n",
    "    @validator(\"input_variables\")\n",
    "    def validate_input_variables(cls, v):\n",
    "        \"\"\" validate that the input variables are correct. \"\"\"\n",
    "        if len(v) != 1 or \"function_name\" not in v:\n",
    "            raise ValueError(\"function_name must be the only input variable.\")\n",
    "        return v\n",
    "    \n",
    "    def format(self, **kwargs) -> str:\n",
    "        # Get the source code of the function \n",
    "        source_code = get_source_code(kwargs[\"function_name\"])\n",
    "        \n",
    "        # Generate the prompt to be sent to the language model\n",
    "        prompt = f\"\"\"\n",
    "        Given the function name and source code, generate an English language explanation of the function.\n",
    "        Function Name: {kwargs[\"function_name\"].__name__}\n",
    "        Source Code:\n",
    "        {source_code}\n",
    "        Explanation:\n",
    "        \"\"\"\n",
    "        return prompt\n",
    "        \n",
    "    def _prompt_type(self):\n",
    "        return \"function-explainer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5071f22e-e415-4e06-a106-ae36534a5b06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now let's generate a custom prompt for our task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4253bdac-e905-4e6b-a256-51eae7ea712f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate a prompt for the function \"get_source_code\"\n",
    "\n",
    "fn_explainer = FunctionExplainerPromptTemplate(input_variables = [\"function_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "643eb176-a5a7-44c3-bae5-3602a99267bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = fn_explainer.format(function_name = get_source_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5697d1c7-68bb-48fb-9546-7dfea47c5b20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Given the function name and source code, generate an English language explanation of the function.\n",
      "        Function Name: get_source_code\n",
      "        Source Code:\n",
      "        def get_source_code(function_name):\n",
      "    # get the source code of the function\n",
      "    return inspect.getsource(function_name)\n",
      "\n",
      "        Explanation:\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0455c2ce-de72-4eb5-a7d7-5a5fb5258931",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global_venv",
   "language": "python",
   "name": "global_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
